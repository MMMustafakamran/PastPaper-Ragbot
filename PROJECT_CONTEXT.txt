================================================================================
PROJECT CONTEXT: MULTI-EXAM PAST PAPERS DATASET BUILDER
================================================================================

PROJECT TYPE: Multi-Exam Dataset Creation Pipeline
PRIMARY GOAL: Build comprehensive question datasets from Pakistani entrance exam 
              past papers (MDCAT, NET, NUST, etc.) for educational AI systems

âš ï¸ SCOPE: This is a data extraction and preprocessing pipeline that handles
         multiple exam formats, both text-based and scanned PDFs.

================================================================================
WHAT THIS PROJECT DOES
================================================================================

INPUT:  Multiple exam past papers in Past Papers/ directory
        - MDCAT: Medical & Dental College Admission Test papers
        - NET: NUST Entry Test papers (selectable & scanned variants)
        - NUST: National University of Sciences & Technology papers

OUTPUT: Structured JSON datasets per exam type in Processed Data/
        - MDCAT/questions.json
        - NET/questions.json
        - etc.

EXTRACTION PIPELINE:
1. PDF Detection â†’ Identify text-based vs scanned PDFs
2. Text Extraction â†’ pdfplumber/PyPDF2 (text) + OCR (scanned)
3. Noise Removal â†’ Filter promotional content, contact info, watermarks
4. Question Parsing â†’ Regex-based segmentation, option detection
5. Classification â†’ Subject area, difficulty, question type
6. Enrichment â†’ Metadata, complexity scores, feature detection
7. Validation â†’ Quality checks, completeness verification
8. JSON Export â†’ Structured output per exam with full metadata

STATUS: ðŸš§ IN PROGRESS - Multi-exam batch processing pipeline

================================================================================
OUTPUT DATA SCHEMA
================================================================================

Each question in data/questions.json has this structure:

{
  "question_number": "1",
  "question_text": "If sinâ»Â¹x + sinâ»Â¹y + sinâ»Â¹z = 3Ï€/2 then...",
  "options": ["a. 0", "b. 1", "c. 2", "d. 3"],
  "answer": null,
  "subject_area": "mathematics",
  "difficulty": "medium",
  "question_type": "multiple_choice",
  "metadata": {
    "has_mathematical_notation": true,
    "has_equations": true,
    "has_functions": true,
    "complexity_score": 2.14,
    "num_options": 4
  },
  "source": "NUST-Engineering-Pastpaper-4(educatedzone.com).pdf"
}

JSON Structure:
- "summary": Stats (subject distribution, difficulty, quality metrics)
- "questions": Array of 199 question objects
- "extraction_metadata": Timestamp, parser version, source file

================================================================================
TARGET EXAM TYPES & SOURCES
================================================================================

MDCAT (Medical & Dental College Admission Test):
- Location: Past Papers/MDCAT/
- Papers: 2008-2020 papers (PMC official papers)
- Subjects: Biology, Chemistry, Physics, English
- Challenge: Mixed scannable/non-scannable formats

NET (NUST Entry Test):
- Location: Past Papers/NET/
- Selectable (text-based PDFs): 5+ papers
- Unselectable (scanned PDFs): 4+ papers requiring OCR
- Subjects: Mathematics, Physics, Chemistry, English, Intelligence
- Challenge: Promotional text ("educatedzone.com", "Download MDCAT Guide App")

NUST Engineering:
- Location: Past Papers/NUST/Engineering/
- Status: Sample extraction completed (199 questions validated)
- Subjects: Mathematics (34%), Chemistry (22%), Physics (14%), English (5%)

COMMON NOISE PATTERNS TO REMOVE:
- "All MDCAT Study Stuff and Free Preparation"
- "Download MDCAT Guide App From Play Store"
- "Helpline 03047418334"
- "www.educatedzone.com"
- Watermarks, website URLs, contact numbers

================================================================================
KEY PARSER CAPABILITIES (src/parser.py - ENHANCED)
================================================================================

1. MULTI-FORMAT PDF HANDLING
   - Auto-detect text-based vs scanned PDFs
   - Text extraction: pdfplumber/PyPDF2 for selectable text
   - OCR: pytesseract/EasyOCR for scanned images
   - Batch processing: Handle entire exam folders

2. NOISE REMOVAL & TEXT CLEANING
   - Filter promotional content (app advertisements, helplines)
   - Remove watermarks and website references
   - Strip contact info (phone numbers, URLs)
   - Clean OCR artifacts and formatting issues
   - Preserve mathematical symbols and special characters

3. QUESTION EXTRACTION
   - Regex pattern matching for question numbers (1. 2. 3...)
   - Multi-line question handling
   - Option detection (a. b. c. d. e.)
   - Context-aware parsing for different exam formats

4. CLASSIFICATION & ENRICHMENT
   - Subject: 7 categories (Math, Physics, Chemistry, Biology, English, 
              Intelligence, General Knowledge)
   - Difficulty: Easy/Medium/Hard based on content analysis
   - Type: Multiple choice, calculation, identification
   - Metadata: Math notation, equations, functions, complexity scores
   - Validation: Question completeness and quality checks

5. OUTPUT FORMATTING
   - JSON per exam type (MDCAT, NET, NUST)
   - Comprehensive metadata and statistics
   - Unicode preservation for scientific notation
   - Source attribution (exam type, year, paper number)

================================================================================
TECHNICAL STACK
================================================================================

LANGUAGE: Python 3.13

PDF EXTRACTION:
- pdfplumber 0.11.7: Primary text extraction for selectable PDFs
- PyPDF2 3.0.1: Fallback PDF reader
- pypdfium2: PDF rendering for OCR preparation

OCR LIBRARIES (for scanned PDFs):
- pytesseract: Tesseract OCR wrapper (PLANNED)
- EasyOCR: Deep learning OCR alternative (PLANNED)
- Pillow (PIL): Image preprocessing for OCR

DATA PROCESSING:
- pandas 2.2.0: DataFrame operations, statistics
- numpy 1.26.3: Numerical operations

TEXT PROCESSING:
- regex (re): Pattern matching, question extraction
- charset-normalizer: Encoding detection

FUTURE RAG INTEGRATION:
- chromadb 0.4.24: Vector database
- sentence-transformers 2.7.0: Embeddings
- streamlit 1.31.0: Web UI

================================================================================
PROJECT STRUCTURE
================================================================================

past-papers-parsing/
â”œâ”€â”€ main.py                          # CLI: python main.py [command] [exam]
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parser.py                    # Core extraction logic
â”‚   â”œâ”€â”€ ocr_handler.py              # OCR processing (PLANNED)
â”‚   â”œâ”€â”€ noise_remover.py            # Text cleaning utilities (PLANNED)
â”‚   â””â”€â”€ batch_processor.py          # Multi-file processing (PLANNED)
â”‚
â”œâ”€â”€ Past Papers/                     # INPUT: Source PDFs
â”‚   â”œâ”€â”€ MDCAT/
â”‚   â”‚   â”œâ”€â”€ mdcat past papers 2008-2019.pdf
â”‚   â”‚   â””â”€â”€ PMC MDCAT PAPER 2020.pdf
â”‚   â”œâ”€â”€ NET/
â”‚   â”‚   â”œâ”€â”€ selectable/             # Text-based PDFs
â”‚   â”‚   â”‚   â”œâ”€â”€ NET-Mathematics-100-MCQs.pdf
â”‚   â”‚   â”‚   â”œâ”€â”€ NUST-Engineering-Pastpaper-4.pdf
â”‚   â”‚   â”‚   â””â”€â”€ PAST NET SERIES 200 MCQS.pdf
â”‚   â”‚   â””â”€â”€ unselectable/           # Scanned PDFs (need OCR)
â”‚   â”‚       â”œâ”€â”€ NUST NET Mathematics Part-1 Mcqs.pdf
â”‚   â”‚       â””â”€â”€ NUST NET Past Paper 1 PLS.pdf
â”‚   â””â”€â”€ NUST/Engineering/
â”‚
â”œâ”€â”€ Extracted Text/                  # INTERMEDIATE: Raw extracted text
â”‚   â”œâ”€â”€ MDCAT/
â”‚   â”œâ”€â”€ NET/
â”‚   â””â”€â”€ NUST/Engineering/
â”‚
â”œâ”€â”€ Processed Data/                  # OUTPUT: Structured JSON datasets
â”‚   â”œâ”€â”€ MDCAT/
â”‚   â”‚   â””â”€â”€ questions.json
â”‚   â””â”€â”€ NET/
â”‚       â””â”€â”€ questions.json
â”‚
â”œâ”€â”€ data/                           # Legacy single-file output
â”‚   â””â”€â”€ questions.json
â”‚
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ PROJECT_CONTEXT.txt            # This file
â””â”€â”€ README.md                      # User guide

================================================================================
USAGE
================================================================================

SETUP:
  python -m venv venv
  venv\Scripts\Activate.ps1   # Windows PowerShell
  pip install -r requirements.txt
  
  # For OCR (scanned PDFs):
  pip install pytesseract easyocr
  # Install Tesseract: https://github.com/tesseract-ocr/tesseract

COMMANDS:

  # Process single exam type
  python main.py parse --exam MDCAT
  python main.py parse --exam NET
  python main.py parse --exam NUST
  
  # Process all exams (batch)
  python main.py parse --all
  
  # Legacy single-file parsing
  python main.py parse
  
  # View statistics
  python main.py stats --exam MDCAT

OUTPUT STRUCTURE:
  Processed Data/MDCAT/questions.json  - MDCAT dataset
  Processed Data/NET/questions.json    - NET dataset
  Extracted Text/MDCAT/*.txt           - Intermediate text files
  Console                              - Real-time progress & statistics

================================================================================
DATASET GOALS & METRICS
================================================================================

TARGET DATASETS:
âœ… MDCAT: 500-1000 questions (Biology, Chemistry, Physics, English)
âœ… NET: 800-1200 questions (Math, Physics, Chemistry, English, Intelligence)
âœ… NUST: 200-400 questions per section

QUALITY TARGETS:
- Accuracy: >95% correct question extraction
- Completeness: >98% questions with 4-5 options
- Clean rate: <2% noise/promotional text in final output
- OCR accuracy: >90% for scanned PDFs

METADATA REQUIREMENTS:
- Source: Exam type, year, paper number
- Subject: Auto-classified with >85% accuracy
- Difficulty: Inferred from question complexity
- Features: Math notation, equations, diagrams (if present)

================================================================================
CHALLENGES & SOLUTIONS
================================================================================

CHALLENGE 1: Mixed PDF formats (text-based vs scanned)
SOLUTION: Implement dual-path processing (pdfplumber + OCR fallback)

CHALLENGE 2: Promotional noise in PDFs
SOLUTION: Pattern-based filtering for common noise strings:
          - App advertisements ("Download MDCAT Guide App")
          - Contact information (phone: 03047418334)
          - Website watermarks (www.educatedzone.com)
          - "All MDCAT Study Stuff and Free Preparation" messages

CHALLENGE 3: OCR accuracy for mathematical equations
SOLUTION: - Use specialized OCR models (MathPix, EasyOCR)
          - Manual review for critical math-heavy questions
          - Preserve original PDF images as fallback

CHALLENGE 4: Different question numbering formats across exams
SOLUTION: Flexible regex patterns per exam type
          - MDCAT: Standard 1. 2. 3. format
          - NET: May include subsections (1a, 1b)
          - Handle both arabic and roman numerals

CHALLENGE 5: Answer keys not always included in PDFs
SOLUTION: Separate answer key parsing or manual annotation phase


================================================================================
CURRENT STATUS & ROADMAP
================================================================================

COMPLETED âœ…:
- Basic PDF text extraction (pdfplumber, PyPDF2)
- Question parsing with regex patterns
- Subject classification (6 categories)
- Metadata enrichment (complexity, features)
- JSON output with statistics
- Sample extraction: 199 NUST Engineering questions

IN PROGRESS ðŸš§:
- Noise removal utilities for promotional content
- Multi-exam batch processing system
- OCR integration for scanned PDFs
- Enhanced subject classification (add Biology)
- Exam-specific output folders

PLANNED ðŸ“‹:
- Tesseract/EasyOCR integration
- Answer key extraction and matching
- Question deduplication across papers
- Image/diagram extraction for visual questions
- Quality validation dashboard
- Automated testing for parser accuracy

================================================================================
END OF CONTEXT
================================================================================
