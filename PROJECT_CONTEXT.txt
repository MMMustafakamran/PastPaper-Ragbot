============
PROJECT CONTEXT: MULTI-EXAM PAST PAPERS DATASET BUILDER
============

PROJECT TYPE: Multi-Exam Dataset Creation Pipeline
PRIMARY GOAL: Build comprehensive question datasets from Pakistani entrance exam 
              past papers (MDCAT, NET, NUST, etc.) for educational AI systems

âš ï¸ SCOPE: This is a data extraction and preprocessing pipeline that handles
         multiple exam formats, both text-based and scanned PDFs.

============
WHAT THIS PROJECT DOES
============

INPUT:  Multiple exam past papers in Past Papers/ directory
        - MDCAT: Medical & Dental College Admission Test papers
        - NET: NUST Entry Test papers (selectable & scanned variants)
        - NUST: National University of Sciences & Technology papers

OUTPUT: Structured JSON datasets per exam type in Processed Data/
        - MDCAT/questions.json
        - NET/questions.json
        - etc.

EXTRACTION PIPELINE:
1. PDF Detection â†’ Identify text-based vs scanned PDFs
2. Text Extraction â†’ pdfplumber/PyPDF2 (text) + OCR (scanned)
3. Noise Removal â†’ Filter promotional content, contact info, watermarks
4. Question Parsing â†’ Regex-based segmentation, option detection
5. Classification â†’ Subject area, difficulty, question type
6. Enrichment â†’ Metadata, complexity scores, feature detection
7. Validation â†’ Quality checks, completeness verification
8. JSON Export â†’ Structured output per exam with full metadata

STATUS: âœ… PHASE 1 COMPLETE - Core modules ready
        ğŸš§ PHASE 2 IN PROGRESS - Batch processing integration

=========
COMPLETE DATA FLOW (How Everything Works Together)
=========
STEP-BY-STEP WORKFLOW:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: PDF INPUT                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Location: Past Papers/MDCAT/selectable/PMC MDCAT PAPER 2020.pdf
   Module: User provides PDF path via CLI
   
   Example: python main.py parse --exam MDCAT --file "PMC MDCAT PAPER 2020.pdf"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: PDF DETECTION (src/pdf_extractor.py)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Class: PDFExtractor
   Method: is_text_selectable(pdf_path)
   
   Actions:
   - Opens PDF with pdfplumber
   - Checks first 3 pages for extractable text
   - Returns: True (text-based) or False (needs OCR)
   
   Output: PDF classification â†’ "selectable" or "scanned"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: TEXT EXTRACTION (src/pdf_extractor.py)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Class: PDFExtractor
   Method: extract_text(pdf_path, method='auto')
   
   For Text-Based PDFs:
   1. extract_text_pdfplumber() - Primary method
   2. extract_text_pypdf2() - Fallback if pdfplumber fails
   
   For Scanned PDFs (future):
   1. OCR with pytesseract/EasyOCR
   
   Output: Raw text string (all pages concatenated)
   Example: "1. What is the atomic number of Carbon?\na. 6\nb. 12..."
   
   Saved to: Extracted Text/MDCAT/PMC_MDCAT_PAPER_2020.txt

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: NOISE REMOVAL (src/noise_remover.py)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Class: NoiseRemover
   Method: clean_text(text, remove_pages=True)
   
   Removes:
   âœ— URLs: www.educatedzone.com, https://...
   âœ— Phone numbers: 03047418334, 0321-1234567
   âœ— Promotional text: "Download MDCAT Guide App From Play Store"
   âœ— App references: "MDCAT Guide App"
   âœ— Email addresses: contact@example.com
   âœ— Social media: Facebook.com/..., @handles
   âœ— Watermarks: "Copyright 2024", "All rights reserved"
   âœ— Page numbers: "Page 1", "- 5 -"
   
   Preserves:
   âœ“ Question numbers: 1. 2. 3.
   âœ“ Options: a. b. c. d. e.
   âœ“ Mathematical symbols: Ï€, âˆš, âˆ‘, âˆ«
   âœ“ Scientific notation: Hâ‚‚O, COâ‚‚
   
   Statistics:
   - Typical noise removal: 40-60% of content
   - Lines removed: ~30-50%
   
   Output: Cleaned text ready for parsing

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: QUESTION PARSING (src/parser.py)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Class: QuestionParser
   Method: extract_questions_from_text(text)
   
   Process:
   1. Split text into lines
   2. Scan for question starts: r'^(\d+)\.\s+(.+)$'
   3. Extract question text
   4. Find following options: r'^([a-e])\.\s*(.+)$'
   5. Handle multi-line questions/options
   6. Create Question objects
   
   Example Detection:
   Input:  "1. What is the atomic number of Carbon?\na. 6\nb. 12\nc. 14\nd. 16"
   
   Parsed:
   - question_number: "1"
   - question_text: "What is the atomic number of Carbon?"
   - options: ["a. 6", "b. 12", "c. 14", "d. 16"]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: SUBJECT CLASSIFICATION (src/parser.py)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Method: _detect_subject_area(question_text)
   
   Keyword Matching for 7 Subjects:
   
   Mathematics: sin, cos, integral, equation, matrix, probability...
   Physics: force, energy, electric, wave, quantum, mechanics...
   Chemistry: atom, molecule, reaction, pH, oxidation, polymer...
   Biology: cell, DNA, protein, mitochondria, photosynthesis... âœ¨ NEW!
   English: synonym, grammar, literature, comprehension...
   Computer Science: algorithm, programming, database...
   General Knowledge: country, award, history, geography...
   
   Scoring:
   - Count keyword matches per subject
   - Subject with highest score wins
   - Default to "general" if no matches
   
   Example:
   "What is the function of mitochondria in cells?"
   â†’ Matches: "function" (biology), "mitochondria" (biology), "cells" (biology)
   â†’ Classified as: Biology (score: 3)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: METADATA ENRICHMENT (src/parser.py)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Method: _extract_metadata(question_text, options)
   
   Detects Features:
   âœ“ has_mathematical_notation: Ï€, âˆš, âˆ‘, âˆ«, âˆ‚
   âœ“ has_equations: =, <, >, â‰¤, â‰¥
   âœ“ has_functions: f(x), g(y), h(z)
   âœ“ has_coordinates: (0,0), (1,-2)
   âœ“ has_angles: 45Â°, 2Ï€
   âœ“ has_chemical_formulas: H2O, CO2
   
   Calculates:
   - complexity_score: 0-5 scale based on length, symbols, notation
   - num_options: Count of answer choices
   - question_length: Character count
   - avg_option_length: Mean length of options
   
   Example Metadata:
   {
     "num_options": 4,
     "has_mathematical_notation": true,
     "has_equations": true,
     "complexity_score": 2.14,
     "question_length": 87
   }

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: VALIDATION (src/parser.py)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Method: validate_question(question)
   
   Checks:
   âœ“ question_number exists
   âœ“ question_text exists and > 10 characters
   âœ“ At least 2 options present
   âœ“ All options non-empty
   
   Invalid Questions Filtered Out:
   âœ— Incomplete extractions
   âœ— Garbage text parsed as questions
   âœ— Header/footer content
   
   Quality Metrics Tracked:
   - Total valid questions
   - Questions with 4 options (standard)
   - Questions with 5 options
   - Subject distribution

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 9: SUMMARY GENERATION (src/parser.py)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Method: generate_comprehensive_summary(questions)
   
   Calculates:
   
   Subject Distribution:
   - Mathematics: 68 (34%)
   - Chemistry: 44 (22%)
   - Biology: 30 (15%)
   - Physics: 28 (14%)
   
   Question Types:
   - multiple_choice: 196
   - calculation: 2
   - identification: 1
   
   Statistics:
   - avg_question_length: 65.3 chars
   - avg_options_per_question: 4.02
   - avg_complexity_score: 1.2
   - questions_with_math_notation: 11
   - questions_with_equations: 40
   
   Quality Metrics:
   - valid_questions: 199/199 (100%)
   - questions_with_4_options: 196 (98.5%)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 10: JSON EXPORT                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Output Structure:
   
   Processed Data/MDCAT/questions.json:
   {
     "summary": { ... statistics ... },
     "questions": [
       {
         "question_number": "1",
         "question_text": "...",
         "options": [...],
         "answer": null,
         "subject_area": "biology",
         "difficulty": "medium",
         "question_type": "multiple_choice",
         "metadata": { ... },
         "source": "PMC MDCAT PAPER 2020.pdf"
       },
       ...
     ],
     "extraction_metadata": {
       "total_lines_processed": 1181,
       "extraction_timestamp": "2024-01-15T10:30:00",
       "parser_version": "3.0",
       "source_file": "PMC MDCAT PAPER 2020.pdf",
       "exam_type": "MDCAT"
     }
   }

==========================================================================================================================================================================================================================================================================================================================
MODULE INTERACTIONS
==========================================================================================================================================================================================================================================================================================================================

main.py (CLI Entry Point)
    â”‚
    â”œâ”€â”€> pdf_extractor.py (PDFExtractor)
    â”‚    â”‚
    â”‚    â”œâ”€â”€> pdfplumber: Primary extraction
    â”‚    â””â”€â”€> PyPDF2: Fallback extraction
    â”‚
    â”œâ”€â”€> noise_remover.py (NoiseRemover)
    â”‚    â”‚
    â”‚    â””â”€â”€> Regex patterns: Clean promotional content
    â”‚
    â””â”€â”€> parser.py (QuestionParser)
         â”‚
         â”œâ”€â”€> Question extraction: Regex parsing
         â”œâ”€â”€> Subject classification: Keyword matching
         â”œâ”€â”€> Metadata enrichment: Feature detection
         â”œâ”€â”€> Validation: Quality checks
         â””â”€â”€> Summary generation: Statistics calculation

DATA FLOW:
    
    PDF File â†’ PDFExtractor.extract_text() â†’ Raw Text String
             â†“
    Raw Text â†’ NoiseRemover.clean_text() â†’ Cleaned Text
             â†“
    Cleaned Text â†’ QuestionParser.extract_questions_from_text()
             â†“
    List[Question Objects] â†’ QuestionParser.validate_question() (filter)
             â†“
    Valid Questions â†’ QuestionParser.generate_comprehensive_summary()
             â†“
    {summary, questions, metadata} â†’ JSON file

ERROR HANDLING:
- PDFExtractor: Falls back to PyPDF2 if pdfplumber fails
- NoiseRemover: Preserves content if patterns don't match
- QuestionParser: Skips invalid questions, continues processing
- Validation: Filters out incomplete/malformed questions

==========================================================================================================================================================================================================================================================================================================================
OUTPUT DATA SCHEMA
==========================================================================================================================================================================================================================================================================================================================

Each question in data/questions.json has this structure:

{
  "question_number": "1",
  "question_text": "If sinâ»Â¹x + sinâ»Â¹y + sinâ»Â¹z = 3Ï€/2 then...",
  "options": ["a. 0", "b. 1", "c. 2", "d. 3"],
  "answer": null,
  "subject_area": "mathematics",
  "difficulty": "medium",
  "question_type": "multiple_choice",
  "metadata": {
    "has_mathematical_notation": true,
    "has_equations": true,
    "has_functions": true,
    "complexity_score": 2.14,
    "num_options": 4
  },
  "source": "NUST-Engineering-Pastpaper-4(educatedzone.com).pdf"
}

JSON Structure:
- "summary": Stats (subject distribution, difficulty, quality metrics)
- "questions": Array of 199 question objects
- "extraction_metadata": Timestamp, parser version, source file

============
TARGET EXAM TYPES & SOURCES
============

MDCAT (Medical & Dental College Admission Test):
- Location: Past Papers/MDCAT/
- Papers: 2008-2020 papers (PMC official papers)
- Subjects: Biology, Chemistry, Physics, English
- Challenge: Mixed scannable/non-scannable formats

NET (NUST Entry Test):
- Location: Past Papers/NET/
- Selectable (text-based PDFs): 5+ papers
- Unselectable (scanned PDFs): 4+ papers requiring OCR
- Subjects: Mathematics, Physics, Chemistry, English, Intelligence
- Challenge: Promotional text ("educatedzone.com", "Download MDCAT Guide App")

NUST Engineering:
- Location: Past Papers/NUST/Engineering/
- Status: Sample extraction completed (199 questions validated)
- Subjects: Mathematics (34%), Chemistry (22%), Physics (14%), English (5%)

COMMON NOISE PATTERNS TO REMOVE:
- "All MDCAT Study Stuff and Free Preparation"
- "Download MDCAT Guide App From Play Store"
- "Helpline 03047418334"
- "www.educatedzone.com"
- Watermarks, website URLs, contact numbers

============
KEY PARSER CAPABILITIES (src/parser.py - ENHANCED)
============

1. MULTI-FORMAT PDF HANDLING
   - Auto-detect text-based vs scanned PDFs
   - Text extraction: pdfplumber/PyPDF2 for selectable text
   - OCR: pytesseract/EasyOCR for scanned images
   - Batch processing: Handle entire exam folders

2. NOISE REMOVAL & TEXT CLEANING
   - Filter promotional content (app advertisements, helplines)
   - Remove watermarks and website references
   - Strip contact info (phone numbers, URLs)
   - Clean OCR artifacts and formatting issues
   - Preserve mathematical symbols and special characters

3. QUESTION EXTRACTION
   - Regex pattern matching for question numbers (1. 2. 3...)
   - Multi-line question handling
   - Option detection (a. b. c. d. e.)
   - Context-aware parsing for different exam formats

4. CLASSIFICATION & ENRICHMENT
   - Subject: 7 categories (Math, Physics, Chemistry, Biology, English, 
              Intelligence, General Knowledge)
   - Difficulty: Easy/Medium/Hard based on content analysis
   - Type: Multiple choice, calculation, identification
   - Metadata: Math notation, equations, functions, complexity scores
   - Validation: Question completeness and quality checks

5. OUTPUT FORMATTING
   - JSON per exam type (MDCAT, NET, NUST)
   - Comprehensive metadata and statistics
   - Unicode preservation for scientific notation
   - Source attribution (exam type, year, paper number)

============
TECHNICAL STACK
============

LANGUAGE: Python 3.13

PDF EXTRACTION:
- pdfplumber 0.11.7: Primary text extraction for selectable PDFs
- PyPDF2 3.0.1: Fallback PDF reader
- pypdfium2: PDF rendering for OCR preparation

OCR LIBRARIES (for scanned PDFs):
- pytesseract: Tesseract OCR wrapper (PLANNED)
- EasyOCR: Deep learning OCR alternative (PLANNED)
- Pillow (PIL): Image preprocessing for OCR

DATA PROCESSING:
- pandas 2.2.0: DataFrame operations, statistics
- numpy 1.26.3: Numerical operations

TEXT PROCESSING:
- regex (re): Pattern matching, question extraction
- charset-normalizer: Encoding detection

FUTURE RAG INTEGRATION:
- chromadb 0.4.24: Vector database
- sentence-transformers 2.7.0: Embeddings
- streamlit 1.31.0: Web UI

============
PROJECT STRUCTURE
============

past-papers-parsing/
â”œâ”€â”€ main.py                          # CLI: python main.py [command] [exam]
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parser.py                    # Core extraction logic
â”‚   â”œâ”€â”€ ocr_handler.py              # OCR processing (PLANNED)
â”‚   â”œâ”€â”€ noise_remover.py            # Text cleaning utilities (PLANNED)
â”‚   â””â”€â”€ batch_processor.py          # Multi-file processing (PLANNED)
â”‚
â”œâ”€â”€ Past Papers/                     # INPUT: Source PDFs
â”‚   â”œâ”€â”€ MDCAT/
â”‚   â”‚   â”œâ”€â”€ mdcat past papers 2008-2019.pdf
â”‚   â”‚   â””â”€â”€ PMC MDCAT PAPER 2020.pdf
â”‚   â”œâ”€â”€ NET/
â”‚   â”‚   â”œâ”€â”€ selectable/             # Text-based PDFs
â”‚   â”‚   â”‚   â”œâ”€â”€ NET-Mathematics-100-MCQs.pdf
â”‚   â”‚   â”‚   â”œâ”€â”€ NUST-Engineering-Pastpaper-4.pdf
â”‚   â”‚   â”‚   â””â”€â”€ PAST NET SERIES 200 MCQS.pdf
â”‚   â”‚   â””â”€â”€ unselectable/           # Scanned PDFs (need OCR)
â”‚   â”‚       â”œâ”€â”€ NUST NET Mathematics Part-1 Mcqs.pdf
â”‚   â”‚       â””â”€â”€ NUST NET Past Paper 1 PLS.pdf
â”‚   â””â”€â”€ NUST/Engineering/
â”‚
â”œâ”€â”€ Extracted Text/                  # INTERMEDIATE: Raw extracted text
â”‚   â”œâ”€â”€ MDCAT/
â”‚   â”œâ”€â”€ NET/
â”‚   â””â”€â”€ NUST/Engineering/
â”‚
â”œâ”€â”€ Processed Data/                  # OUTPUT: Structured JSON datasets
â”‚   â”œâ”€â”€ MDCAT/
â”‚   â”‚   â””â”€â”€ questions.json
â”‚   â””â”€â”€ NET/
â”‚       â””â”€â”€ questions.json
â”‚
â”œâ”€â”€ data/                           # Legacy single-file output
â”‚   â””â”€â”€ questions.json
â”‚
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ PROJECT_CONTEXT.txt            # This file
â””â”€â”€ README.md                      # User guide

============
USAGE
============

SETUP:
  python -m venv venv
  venv\Scripts\Activate.ps1   # Windows PowerShell
  pip install -r requirements.txt
  
  # For OCR (scanned PDFs):
  pip install pytesseract easyocr
  # Install Tesseract: https://github.com/tesseract-ocr/tesseract

COMMANDS:

  # Process single exam type
  python main.py parse --exam MDCAT
  python main.py parse --exam NET
  python main.py parse --exam NUST
  
  # Process all exams (batch)
  python main.py parse --all
  
  # Legacy single-file parsing
  python main.py parse
  
  # View statistics
  python main.py stats --exam MDCAT

OUTPUT STRUCTURE:
  Processed Data/MDCAT/questions.json  - MDCAT dataset
  Processed Data/NET/questions.json    - NET dataset
  Extracted Text/MDCAT/*.txt           - Intermediate text files
  Console                              - Real-time progress & statistics

============
DATASET GOALS & METRICS
============

TARGET DATASETS:
âœ… MDCAT: 500-1000 questions (Biology, Chemistry, Physics, English)
âœ… NET: 800-1200 questions (Math, Physics, Chemistry, English, Intelligence)
âœ… NUST: 200-400 questions per section

QUALITY TARGETS:
- Accuracy: >95% correct question extraction
- Completeness: >98% questions with 4-5 options
- Clean rate: <2% noise/promotional text in final output
- OCR accuracy: >90% for scanned PDFs

METADATA REQUIREMENTS:
- Source: Exam type, year, paper number
- Subject: Auto-classified with >85% accuracy
- Difficulty: Inferred from question complexity
- Features: Math notation, equations, diagrams (if present)

============
CHALLENGES & SOLUTIONS
============

CHALLENGE 1: Mixed PDF formats (text-based vs scanned)
SOLUTION: Implement dual-path processing (pdfplumber + OCR fallback)

CHALLENGE 2: Promotional noise in PDFs
SOLUTION: Pattern-based filtering for common noise strings:
          - App advertisements ("Download MDCAT Guide App")
          - Contact information (phone: 03047418334)
          - Website watermarks (www.educatedzone.com)
          - "All MDCAT Study Stuff and Free Preparation" messages

CHALLENGE 3: OCR accuracy for mathematical equations
SOLUTION: - Use specialized OCR models (MathPix, EasyOCR)
          - Manual review for critical math-heavy questions
          - Preserve original PDF images as fallback

CHALLENGE 4: Different question numbering formats across exams
SOLUTION: Flexible regex patterns per exam type
          - MDCAT: Standard 1. 2. 3. format
          - NET: May include subsections (1a, 1b)
          - Handle both arabic and roman numerals

CHALLENGE 5: Answer keys not always included in PDFs
SOLUTION: Separate answer key parsing or manual annotation phase


============
CURRENT STATUS & ROADMAP
============

COMPLETED âœ…:
- Basic PDF text extraction (pdfplumber, PyPDF2)
- Question parsing with regex patterns
- Subject classification (6 categories)
- Metadata enrichment (complexity, features)
- JSON output with statistics
- Sample extraction: 199 NUST Engineering questions

IN PROGRESS ğŸš§:
- Noise removal utilities for promotional content
- Multi-exam batch processing system
- OCR integration for scanned PDFs
- Enhanced subject classification (add Biology)
- Exam-specific output folders

PLANNED ğŸ“‹:
- Tesseract/EasyOCR integration
- Answer key extraction and matching
- Question deduplication across papers
- Image/diagram extraction for visual questions
- Quality validation dashboard
- Automated testing for parser accuracy

============
END OF CONTEXT
============
